{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fce70c-f861-43c6-bb42-0d1e2b805bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747898810.394757 10866783 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1747898810.463894 10866986 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747898810.472023 10866986 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747898811.901248 10866986 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기준 자세 저장 완료!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sys\n",
    "import serial\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "# drawio seq1\n",
    "# ====================== 초기화 함수 ======================\n",
    "\n",
    "def init_arduino(port='/dev/tty.usbmodem1101', baudrate=9600):\n",
    "    return serial.Serial(port, baudrate)\n",
    "\n",
    "def init_mediapipe():\n",
    "    mp_pose = mp.solutions.pose\n",
    "    return mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=0,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    \n",
    "def init_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow('Posture Detection', cv2.WINDOW_NORMAL)\n",
    "    return cap\n",
    "\n",
    "# ====================== 기능 함수 ======================\n",
    "\n",
    "def get_landmark_positions(pose_landmarks, image_width, image_height):\n",
    "    # 어깨 중앙점 계산\n",
    "    left_shoulder = pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER]\n",
    "    right_shoulder = pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "    \n",
    "    # 입 좌표 계산\n",
    "    mouth_left = pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.MOUTH_LEFT]\n",
    "    mouth_right = pose_landmarks.landmark[mp.solutions.pose.PoseLandmark.MOUTH_RIGHT]\n",
    "    \n",
    "    # 어깨 중앙점 계산\n",
    "    shoulder_mid_x = (left_shoulder.x + right_shoulder.x) / 2\n",
    "    shoulder_mid_y = (left_shoulder.y + right_shoulder.y) / 2\n",
    "    \n",
    "    # 입 중앙점 계산\n",
    "    mouth_mid_x = (mouth_left.x + mouth_right.x) / 2\n",
    "    mouth_mid_y = (mouth_left.y + mouth_right.y) / 2\n",
    "    \n",
    "    return {\n",
    "        'shoulder_mid': (int(shoulder_mid_x * image_width), int(shoulder_mid_y * image_height)),\n",
    "        'mouth_mid': (int(mouth_mid_x * image_width), int(mouth_mid_y * image_height)),\n",
    "        'mouth_y': int(mouth_mid_y * image_height),\n",
    "        'shoulder_mid_y': int(shoulder_mid_y * image_height)\n",
    "    }\n",
    "\n",
    "def draw_baseline_guidance(image, font):\n",
    "    cv2.putText(image, \"Sit upright and press 'S' to save baseline\", (20, 60), font, 0.8, (0, 0, 255), 2)\n",
    "    center_x, center_y = image.shape[1] // 2 + 50, image.shape[0] // 2\n",
    "    axes_length = (200, 300)\n",
    "    cv2.ellipse(image, (center_x, center_y), axes_length, 0, 0, 360, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "def calculate_score_from_landmarks(baseline, current):\n",
    "    \"\"\"\n",
    "    입과 어깨 중앙점의 상대적 위치 변화로 거북목 점수를 계산.\n",
    "    - 기준값은 함수 내부에서 설정됨\n",
    "    - 입과 어깨 사이의 거리 변화를 기반으로 계산\n",
    "    \"\"\"\n",
    "    \n",
    "    # ✅ 기준값 정의\n",
    "    distance_thresh = 100  # 픽셀 기준 거리 변화 허용치\n",
    "    \n",
    "    # ✅ 값 추출\n",
    "    baseline_mouth_y = baseline['mouth_y']\n",
    "    baseline_shoulder_y = baseline['shoulder_mid_y']\n",
    "    current_mouth_y = current['mouth_y']\n",
    "    current_shoulder_y = current['shoulder_mid_y']\n",
    "    \n",
    "    \n",
    "    # ✅ 기준 자세에서의 거리\n",
    "    baseline_distance = abs(baseline_mouth_y - baseline_shoulder_y)\n",
    "    current_distance = abs(current_mouth_y - current_shoulder_y)\n",
    "    \n",
    "    # ✅ 거리 변화량 계산\n",
    "    distance_diff = baseline_distance-current_distance\n",
    "    \n",
    "    # ✅ 정규화 점수 계산\n",
    "    score = min(max((distance_diff / distance_thresh) * 100, 0), 100)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def handle_posture_feedback(score, font, image, arduino):\n",
    "    if score > 80:\n",
    "        cv2.putText(image, \"Stage 2 Warning: Severe posture issue!\", (20, 120), font, 0.8, (0, 0, 255), 2)\n",
    "        arduino.write(b'2')\n",
    "    elif score >= 50:\n",
    "        cv2.putText(image, \"Stage 1 Warning: Please fix your posture!\", (20, 120), font, 0.8, (0, 165, 255), 2)\n",
    "        arduino.write(b'1')\n",
    "    else:\n",
    "        arduino.write(b'0')\n",
    "\n",
    "def handle_stretch_session(arduino):\n",
    "    if not pygame.mixer.music.get_busy():\n",
    "        pygame.mixer.music.play()\n",
    "    arduino.write(b'3')\n",
    "\n",
    "# ====================== 메인 ======================\n",
    "\n",
    "def main():\n",
    "    pygame.init()\n",
    "    pygame.mixer.init()\n",
    "    try:\n",
    "        pygame.mixer.music.load(\"alpacca_sound.wav\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ 사운드 파일 로딩 실패:\", e)\n",
    "        return\n",
    "        \n",
    "    arduino = init_arduino()\n",
    "    pose = init_mediapipe()\n",
    "    cap = init_camera()\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "    baseline_landmarks = None\n",
    "    measured = False\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image_rgb)\n",
    "        image_height, image_width, _ = image.shape\n",
    "        key = cv2.waitKey(5)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = get_landmark_positions(results.pose_landmarks, image_width, image_height)\n",
    "\n",
    "            # 랜드마크 표시\n",
    "            cv2.circle(image, landmarks['shoulder_mid'], 4, (0, 255, 0), -1)\n",
    "            cv2.circle(image, landmarks['mouth_mid'], 4, (0, 0, 255), -1)\n",
    "         \n",
    "\n",
    "            if not measured:\n",
    "                draw_baseline_guidance(image, font)\n",
    "                if key == ord('s'):\n",
    "                    baseline_landmarks = landmarks\n",
    "                    measured = True\n",
    "                    print(\"✅ 기준 자세 저장 완료!\")\n",
    "            else:\n",
    "                score = calculate_score_from_landmarks(baseline_landmarks, landmarks)\n",
    "                cv2.putText(image, f'Turtle Neck Score: {score:.1f}/100', (20, 80), font, 0.8, (0, 100, 255), 2)\n",
    "                handle_posture_feedback(score, font, image, arduino)\n",
    "\n",
    "        cv2.imshow('Posture Detection', image)\n",
    "\n",
    "        if key == ord('m'):\n",
    "            handle_stretch_session(arduino)\n",
    "\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    sys.exit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87a258-74db-484f-9810-ef5f6ec59959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bbd3f3-c0e2-47ef-9aa9-677decfe8a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
